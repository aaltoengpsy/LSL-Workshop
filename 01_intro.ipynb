{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Lab Streaming Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This workshop will go over the basics of using LSL, in combination with Python, for research. To read more about its inner workings or find out about language support, you can head over to [the official documentation](https://labstreaminglayer.readthedocs.io/index.html). The [FAQs](https://labstreaminglayer.readthedocs.io/info/faqs.html) page specifically might be helpful if you're writing more advanced solutions. There's also [a paper](https://link.springer.com/article/10.1007/s10055-023-00799-8) about the use of LSL for VR/AR research."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's LSL and why should I use it?\n",
    "\n",
    "When collecting research data, you usually collect **samples** measuring the state of a variable, whether it's air humidity, heart rate or accelerometer data, at different points in time. Handling certain aspects of data collection can, however, be tricky - especially if multiple variables are sampled using multiple different devices. How do you know when a sample was collected? How do you transmit data wirelessly? How do you handle reading and synchronizing data from multiple sources?\n",
    "\n",
    "All of the issues above are fairly straightforward to solve yourself if you have the time and know-how. That said, in research, the case often might be that you do not. Moreover, custom time logging without clock drift adjustment can lead to corrupted or otherwise unusable data, which is why it's generally recommended not to reinvent the wheel and use a tried and tested solution. After all, research is all about data. **When developing research software, your primary concern is ensuring the safety and accuracy of that data.**\n",
    "\n",
    "But wouldn't it be twice as good if your time logging solution could also handle multiple data sources and even networking out-of-the-box?\n",
    "\n",
    "Well, as it turns out, lab streaming layer (LSL) offers just that with interfaces for a range of programming languages (including Python, which we'll be using going forward in this workshop) and [quite an impressive list of supported devices](https://labstreaminglayer.readthedocs.io/info/supported_devices.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Streams and the LSL Network\n",
    "\n",
    "Within the LSL context, all data is handled as **streams**. Each stream carries time-series data of a certain pre-defined type; i.e. in a single stream, all values have to be of a certain type. Streams can, however, embed multichannel data in the case of, for example, EEG. Streamed data does not have to be continuous: you can use a stream to send event markers for practically anything.\n",
    "\n",
    "The **network** within the LSL context is not exactly a well-defined concept. Essentially, it is a collection of streams of data that can be accessed from any device within the network and which adhere to the same time format, making synchronization simple when data is analyzed later on. LSL establishes itself on the local network, essentially meaning that **the LSL \"network\" is any network used to transmit LSL data**. This also means that (in theory, if firewall configurations are correct), any device within the same W/LAN can access data streamed with LSL as long as stream identifiers are known. This makes it easy to use multiple devices for multiple purposes (e.g. one for streaming data from one source, a second one for streaming from a second source, and a third one for recording only). Unfortunately, it also has implications for privacy and security: since LSL does not in itself enforce authentication, the network being used to transmit LSL data should be secured to prevent outsiders from listening in to the data being streamed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inlets and Outlets\n",
    "\n",
    "Now we know what the LSL network is in essence: a collection of data streams. But how do we push data to the network or access data already within it?\n",
    "\n",
    "To push a data stream to the network, an **outlet** is required. Outlets push data streams to the network either sample-by-sample (meaning that individual variable readings are pushed on their own) or, depending on configuration, in **chunks**, which are packages consisting of multiple samples. Wrapping samples into chunks can help manage bandwith when large amounts of data are being streamed in the network.\n",
    "\n",
    "**Inlets**, in turn, are used to access data streamed to the network. Once a stream has been identified (or \"**resolved**\" in the LSL vocabulary), it can be connected to an outlet, after which samples (or chunks) can be pulled for further processing, such as displaying or logging.\n",
    "\n",
    "> The concepts of inlets and outlets might seem backwards at first - after all, from the network's perspective, shouldn't an inlet be a data source and an outlet a \"drain\"? It might help to think of the LSL network as a data \"river\". In this analogy, an outlet is a \"drainage pipe\" from which a certain type of data (a stream) is dumped to the river, while inlets are used to source and filter selected data from the river."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Conclusion\n",
    "\n",
    "You should now have a grasp of the core concepts you need to use LSL. In summary, **samples** are **streamed** through an **outlet** to the LSL **network**. **Inlets** are used to capture data streams within the network in order to process them.\n",
    "\n",
    "![](./images/lsl-structure.drawio.png)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
